{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import dnnlib\n",
    "import dnnlib.tflib as tflib\n",
    "import config\n",
    "from encoder.generator_model import Generator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL_FFHQ = 'https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ'\n",
    "FILE_FFHQ = os.path.join(\"models\", \"karras2019stylegan-ffhq-1024x1024.pkl\")\n",
    "\n",
    "tflib.init_tf()\n",
    "with open(FILE_FFHQ, \"rb\") as f:\n",
    "    generator_network, discriminator_network, Gs_network = pickle.load(f)\n",
    "#with dnnlib.util.open_url(URL_FFHQ, cache_dir=config.cache_dir) as f:\n",
    "    #generator_network, discriminator_network, Gs_network = pickle.load(f)\n",
    "\n",
    "generator = Generator(Gs_network, batch_size=1, randomize_noise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(latent_vector):\n",
    "    latent_vector = latent_vector.reshape((1, 18, 512))\n",
    "    generator.set_dlatents(latent_vector)\n",
    "    img_array = generator.generate_images()[0]\n",
    "    img = PIL.Image.fromarray(img_array, 'RGB')\n",
    "    return img.resize((256, 256)), img\n",
    "\n",
    "def move_and_show(latent_vector, direction, coeffs, save=True):\n",
    "    fig,ax = plt.subplots(1, len(coeffs), figsize=(15, 10), dpi=80)\n",
    "    for i, coeff in enumerate(coeffs):\n",
    "        new_latent_vector = latent_vector.copy()\n",
    "        new_latent_vector[:8] = (latent_vector + coeff*direction)[:8]\n",
    "        gen_image, gen_image_full = generate_image(new_latent_vector)\n",
    "        ax[i].imshow(gen_image)\n",
    "        ax[i].set_title('Coeff: %0.1f' % coeff)\n",
    "        if save:\n",
    "            gen_image_full.save(os.path.join(\"moved_images\", str(i) + \".jpg\"))\n",
    "    [x.axis('off') for x in ax]\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading already learned representations\n",
    "donald_trump = np.load('ffhq_dataset/latent_representations/donald_trump_01.npy')\n",
    "hillary_clinton = np.load('ffhq_dataset/latent_representations/hillary_clinton_01.npy')\n",
    "\n",
    "face_065 = np.load('latent_representations/ffhq/face_065_01.npy')\n",
    "my_face_02 = np.load('latent_representations/ffhq/my_face_02_01.npy')\n",
    "mimosa = np.load('latent_representations/ffhq/mimosa.npy')\n",
    "notre_dame_2_square = np.load('latent_representations/ffhq/notre_dame_2_square.npy')\n",
    "salveenee = np.load('latent_representations/ffhq/salveenee-600_jpg_1400x0_q85_01_aligned.npy')\n",
    "marissa = np.load('latent_representations/ffhq/seed_56_example_781.npy')\n",
    "pania_di_corfino = np.load('latent_representations/ffhq/pania_di_corfino.npy')\n",
    "# Of course you can learn your own vectors using two scripts\n",
    "\n",
    "# 1) Extract and align faces from images\n",
    "# python align_images.py raw_images/ aligned_images/\n",
    "\n",
    "# 2) Find latent representation of aligned images\n",
    "# python encode_images.py aligned_images/ generated_images/ latent_representations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading already learned latent directions\n",
    "smile_direction = np.load('ffhq_dataset/latent_directions/smile.npy')\n",
    "gender_direction = np.load('ffhq_dataset/latent_directions/gender.npy')\n",
    "age_direction = np.load('ffhq_dataset/latent_directions/age.npy')\n",
    "\n",
    "random_direction = np.random.rand(*age_direction.shape).astype(age_direction.dtype)\n",
    "\n",
    "# In general it's possible to find directions of almost any face attributes: position, hair style or color ... \n",
    "# Additional scripts for doing so will be realised soon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smile transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move_and_show(donald_trump, smile_direction, [-1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move_and_show(hillary_clinton, smile_direction, [-1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_and_show(marissa, smile_direction, [-0.5, 0, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_and_show(salveenee, smile_direction, [-1.5, 0, 1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_and_show(pania_di_corfino, smile_direction, [-2.0, 0, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_and_show(donald_trump, gender_direction, [-2, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_and_show(hillary_clinton, gender_direction, [-1.5, 0, 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_and_show(marissa, gender_direction, [-40, 0, 3.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_and_show(pania_di_corfino, gender_direction, [-5, 0, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_and_show(salveenee, gender_direction, [-3, 0, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_and_show(notre_dame_2_square, gender_direction, [-1, 0, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_and_show(hillary_clinton, age_direction, [-2, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "move_and_show(donald_trump, age_direction, [-3, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_and_show(marissa, age_direction, [-5, 0, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_and_show(pania_di_corfino, age_direction, [-5, 0, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_and_show(salveenee, age_direction, [-5, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_and_show(notre_dame_2_square, age_direction, [-10, 0, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_and_show(notre_dame_2_square, random_direction, [-0.1, 0, 0.04])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_and_show(marissa, random_direction, [-0.23, 0, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_and_show(pania_di_corfino, random_direction, [-1, 0, 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_and_show(salveenee, random_direction, [-0.1, 0, 0.0778])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
